{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pathlib\n",
    "import logging\n",
    "\n",
    "from _create_model_util import create_character_model\n",
    "from _dataset_util import create_dataset_for_training"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configuration ðŸ”§ðŸ”¨ðŸ”¨ðŸ”©"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.basicConfig(level=logging.INFO)\n",
    "\n",
    "\n",
    "URL = \"../data/tinyshakespeare.txt\"\n",
    "BUFFER_SIZE = 10000\n",
    "VOCAB_SIZE = 66\n",
    "BLOCK_SIZE = 100\n",
    "BATCH_SIZE = 64\n",
    "DIMS = 512\n",
    "NUM_HEADS = 4\n",
    "FFNN_UNITS = 2048\n",
    "DROPOUT_RATE = 0.2\n",
    "NUM_DECODER_LAYERS = 4"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:[TASK] >>>>> Create Training Dataset ðŸ’¾\n",
      "INFO:root:Reading-Data...\n",
      "INFO:root:Creating-vocab-maps...\n",
      "INFO:root:Mapping: map string to integer ids...\n",
      "INFO:root:Creating fixed length sequences...\n",
      "INFO:root:Fixed length Sequence created : block size = 101 \n",
      "INFO:root:Creating-Datset: batch size = 64\n",
      "INFO:root:[JOB FINISHED] >>>>> Training Dataset created ðŸ’¾ âœ…\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# getting data\n",
    "dataset, mapper = create_dataset_for_training(\n",
    "    url=URL, block_size=BLOCK_SIZE+1, batch_size=BATCH_SIZE, buffer_size=BUFFER_SIZE)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating Model ðŸ¤–"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:[TASK] >>>>> Creating Character Model\n",
      "INFO:root:[TASK] >>>>> Create Tensorflow character model ðŸ¤–\n",
      "INFO:root:[JOB FINISHED] >>>>> Tensorflow character model ðŸ¤– âœ…\n",
      "INFO:root:\n",
      "âœ… Character Model Configuration ðŸ¤–ðŸ”§ðŸ”§\n",
      "\n",
      ":::::::::::::::::::::::\n",
      "\n",
      "ðŸ“–VOCAB_SIZE = 66\n",
      "\n",
      "ðŸš¥BLOCK_SIZE = 100\n",
      "\n",
      "ðŸš¥BATCH_SIZE = 64\n",
      "\n",
      "ðŸš¥DIMS = 512\n",
      "\n",
      "ðŸ”¨NUM_HEADS = 4\n",
      "\n",
      "ðŸ”©FFNN_UNITS = 2048\n",
      "\n",
      "ðŸª‚DROPOUT_RATE = 0.2\n",
      "\n",
      "ðŸ”§NUM_DECODER_LAYERS = 4\n",
      "\n",
      ":::::::::::::::::::::::\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "message = f'''\n",
    "âœ… Character Model Configuration ðŸ¤–ðŸ”§ðŸ”§\\n\n",
    ":::::::::::::::::::::::\\n\n",
    "ðŸ“–VOCAB_SIZE = {VOCAB_SIZE}\\n\n",
    "ðŸš¥BLOCK_SIZE = {BLOCK_SIZE}\\n\n",
    "ðŸš¥BATCH_SIZE = {BATCH_SIZE}\\n\n",
    "ðŸš¥DIMS = {DIMS}\\n\n",
    "ðŸ”¨NUM_HEADS = {NUM_HEADS}\\n\n",
    "ðŸ”©FFNN_UNITS = {FFNN_UNITS}\\n\n",
    "ðŸª‚DROPOUT_RATE = {DROPOUT_RATE}\\n\n",
    "ðŸ”§NUM_DECODER_LAYERS = {NUM_DECODER_LAYERS}\\n\n",
    ":::::::::::::::::::::::\\n\n",
    "'''\n",
    "logging.info('[TASK] >>>>> Creating Character Model')\n",
    "model = create_character_model(\n",
    "    VOCAB_SIZE, BLOCK_SIZE, NUM_DECODER_LAYERS, NUM_HEADS, DIMS, FFNN_UNITS, DROPOUT_RATE)\n",
    "\n",
    "logging.info(message)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:[COMPILE THE MODEL]: Adam as optimizer, SparseCategorialCrossentropy as loss-function\n",
      "INFO:root:Model Evaluation ðŸ§¾\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 49s 3s/step - loss: 5.0816 - accuracy: 0.0239\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[5.0815534591674805, 0.023874999955296516]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# compile the model\n",
    "logging.info('[COMPILE THE MODEL]: Adam as optimizer, SparseCategorialCrossentropy as loss-function')\n",
    "model.compile(\n",
    "    optimizer='adam', \n",
    "    loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "    metrics=['accuracy'])\n",
    "\n",
    "\n",
    "logging.info('Model Evaluation ðŸ§¾')\n",
    "model.evaluate(dataset.take(10))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.checkpoint.checkpoint.CheckpointLoadStatus at 0x19b071673d0>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_weights('./saved_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Model Evaluation ðŸ§¾\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 28s 3s/step - loss: 1.2636 - accuracy: 0.6043\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1.263580322265625, 0.6043437719345093]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logging.info('Model Evaluation ðŸ§¾')\n",
    "model.evaluate(dataset.take(10))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TextGeneration(tf.Module):\n",
    "    def __init__(self, model, mapper, block_size):\n",
    "        super(TextGeneration, self).__init__()\n",
    "        self.model = model\n",
    "        self.mapper = mapper\n",
    "        self.BLOCK_SIZE = block_size\n",
    "\n",
    "    def process_input(self, data):\n",
    "        characters = tf.strings.unicode_split(data, 'UTF-8')\n",
    "        ragged = self.mapper['char_to_id'](characters)\n",
    "        tensor = tf.keras.utils.pad_sequences(ragged.numpy(), maxlen=self.BLOCK_SIZE, value=2)\n",
    "        return tensor\n",
    "\n",
    "    def sampling(self, predictions):\n",
    "        last = predictions[:, -1, :]\n",
    "        samples = tf.random.categorical(logits=last, num_samples=1)\n",
    "        return samples\n",
    "\n",
    "\n",
    "    def __call__(self, inputs, n_iter=300):\n",
    "        inputs = self.process_input(inputs)\n",
    "\n",
    "        for i in tf.range(n_iter):\n",
    "            # [batch, seq] --> [batch, seq, vocab-size]\n",
    "            preds = self.model(inputs[:,-self.BLOCK_SIZE:])\n",
    "            # [batch, seq, vocab-size] --> [batch, 1]\n",
    "            outputs = self.sampling(preds)\n",
    "            # concat inputs\n",
    "            inputs = tf.concat(values=[inputs, outputs], axis=-1)\n",
    "        \n",
    "        \n",
    "        outputs = self.mapper['id_to_str'](inputs)\n",
    "        return outputs\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_gen = TextGeneration(model=model, mapper=mapper, block_size=BLOCK_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_sample_inputs = [\n",
    "\"\"\"GLOUCESTER:\n",
    "Two of thy name, both Dukes of Somerset,\n",
    "Have sold their lives unto the house of York.\"\"\",\n",
    "\n",
    "\"\"\"KING EDWARD IV:\n",
    "Now welcome more, and ten times more beloved,\n",
    "Than if thou never hadst deserved our hate.\"\"\" ,\n",
    "\n",
    "\"\"\"FRIAR LAURENCE:\n",
    "Hence from Verona art thou banished:\n",
    "Be patient, for the world is broad and wide.\"\"\"  ,\n",
    "\n",
    "\"\"\"\n",
    "PETRUCHIO:\n",
    "How but well, sir? how but well?\n",
    "It were impossible I should speed amiss.\n",
    "\n",
    "BAPTISTA:\n",
    "\"\"\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = text_gen(tf_sample_inputs, n_iter=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  GLOUCESTER:\n",
      "Two of thy name, both Dukes of Somerset,\n",
      "Have sold their lives unto the house of York.\n",
      "\n",
      "ELBOW:\n",
      "Are yet think runk so say's numbility.\n",
      "\n",
      "JOHN OF GAUNT:\n",
      "And see the best propherous or no, t\n",
      "----------------------------------------------------------------------------------------------------\n",
      "EDWARD IV:\n",
      "Now welcome more, and ten times more beloved,\n",
      "Than if thou never hadst deserved our hate.\n",
      "\n",
      "JULIET:\n",
      "Tut, have I going in his head\n",
      "disconclaims: If thou art our royalting-tast,\n",
      "For kissh, nev\n",
      "----------------------------------------------------------------------------------------------------\n",
      "   FRIAR LAURENCE:\n",
      "Hence from Verona art thou banished:\n",
      "Be patient, for the world is broad and wide.\n",
      "\n",
      "BRUTUS:\n",
      "We'll devine, is newly succurpet:\n",
      "Nor one deserved the maids, we'll come to know other.\n",
      "\n",
      "B\n",
      "----------------------------------------------------------------------------------------------------\n",
      "   \n",
      "PETRUCHIO:\n",
      "How but well, sir? how but well?\n",
      "It were impossible I should speed amiss.\n",
      "\n",
      "BAPTISTA:\n",
      "Sir, my good lord; you go marry, I reseem his ladce,\n",
      "That speaks for dome it your man begied and dis\n",
      "----------------------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "for res in response:\n",
    "    print(res.numpy().decode('utf-8'))\n",
    "    print('-'*100)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "ragged = tf.strings.unicode_split(tf_sample_inputs, 'UTF-8')\n",
    "ragged =  mapper['char_to_id'](ragged)\n",
    "fixed_length = tf.keras.utils.pad_sequences(ragged.numpy(), maxlen=100, value=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = fixed_length\n",
    "for i in range(300):\n",
    "    # [batch, seq] --> [batch, seq, vocab_size]\n",
    "    pred = model(inputs)\n",
    "    # [batch, seq, vocab_size] --> [batch, 1]\n",
    "    pred = tf.random.categorical(logits=pred[:,-1,:], num_samples=1)\n",
    "    fixed_length = tf.concat(values=[fixed_length, pred], axis=-1)\n",
    "    inputs = fixed_length[:,-100:]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_output = mapper['id_to_str'](fixed_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  GLOUCESTER:\n",
      "Two of thy name, both Dukes of Somerset,\n",
      "Have sold their lives unto the house of York.\n",
      "\n",
      "First Murderer:\n",
      "Had now may heard a thing too the old runks\n",
      "thread gave and goals pardon of early know\n",
      "They among there; when so pretty in the city\n",
      "Most were going to crowns' the nature of king.\n",
      "\n",
      "LEONTES:\n",
      "When show you live me?\n",
      "\n",
      "JULIET:\n",
      "I would see you his enough bare to his name;\n",
      "But you have mus\n"
     ]
    }
   ],
   "source": [
    "print(final_output[0].numpy().decode('utf-8'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EDWARD IV:\n",
      "Now welcome more, and ten times more beloved,\n",
      "Than if thou never hadst deserved our hate.\n",
      "Faith, no, we do not summmon to heart: 'Tis come,' for me!\n",
      "We kissed.\n",
      "I know news the fives will trust keys;\n",
      "He fair knows, number's as thy king, and oshe\n",
      "silence give my gage, as She is nearder his seas fear?\n",
      "Thou is for thus to the high: what fair sorts and sulls\n",
      "last before so our turn are as co\n"
     ]
    }
   ],
   "source": [
    "print(final_output[1].numpy().decode('utf-8'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   FRIAR LAURENCE:\n",
      "Hence from Verona art thou banished:\n",
      "Be patient, for the world is broad and wide.\n",
      "\n",
      "FNGRIARD:\n",
      "What she aswer\n",
      "Is true approach they do pine.\n",
      "\n",
      "PONIS:\n",
      "A maid lade prepared among clamous brand some steads,\n",
      "Though I takest or a mality;\n",
      "Who now, my soul as Gremio is tunenown to our kisses.\n",
      "\n",
      "PETRUCHIO:\n",
      "Nay, Let me come more my great lord. O, but knock I fought and as this beauty,\n",
      "Good a\n"
     ]
    }
   ],
   "source": [
    "print(final_output[2].numpy().decode('utf-8'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   FRIAR LAURENCE:\n",
      "Hence from Verona art thou banished:\n",
      "Be patient, for the world is broad and wide.\n",
      "\n",
      "FNGRIARD:\n",
      "What she aswer\n",
      "Is true approach they do pine.\n",
      "\n",
      "PONIS:\n",
      "A maid lade prepared among clamous brand some steads,\n",
      "Though I takest or a mality;\n",
      "Who now, my soul as Gremio is tunenown to our kisses.\n",
      "\n",
      "PETRUCHIO:\n",
      "Nay, Let me come more my great lord. O, but knock I fought and as this beauty,\n",
      "Good a\n"
     ]
    }
   ],
   "source": [
    "print(final_output[2].numpy().decode('utf-8'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   \n",
      "PETRUCHIO:\n",
      "How but well, sir? how but well?\n",
      "It were impossible I should speed amiss.\n",
      "\n",
      "BAPTISTA:\n",
      "Great makes not to Petruchio, go sleep in their house.\n",
      "\n",
      "PETRUCHIO:\n",
      "I promise! prison, Signior Grant Jupy up.\n",
      "\n",
      "VINCENTIO:\n",
      "Aknows boy!\n",
      "\n",
      "AUFIDIUS:\n",
      "Not the extremity weep, how to they?\n",
      "\n",
      "CLAUDIO:\n",
      "The come;\n",
      "And for burthen his loves honour truly, Aughs Tybalt you.\n",
      "\n",
      "SICINIUS:\n",
      "Where's depleases me?\n",
      "\n",
      "Pedant:\n"
     ]
    }
   ],
   "source": [
    "print(final_output[3].numpy().decode('utf-8'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
